{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我在 Tensorflow 官網的教學網頁上找到了用 Iris 當例題的 estimator tutorial https://www.tensorflow.org/versions/master/get_started/premade_estimators (also on my Ynote \"Get Started with Estimators _TensorFlow_\") 有正式、詳細的介紹。\n",
    "這篇文章鼓勵人用 Estimator API 跟 Dataset API。本文研讀、實驗這篇文章。\n",
    "文章引用的 GitHub resource 我已經 clone 下來了在 T550 `c:\\Users\\hcche\\Documents\\GitHub\\models`  \n",
    "\n",
    "重點是，直接用 pandas data-frame 來當作 feature - label 餵給 input function 這樣更自然，免去搞 150 天行情資料的麻煩。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reDef \\\n"
     ]
    }
   ],
   "source": [
    "import peforth\n",
    "peforth.dictate(r'''\n",
    "\\ Now we redefine the 'unknown' command that was do-nothing by default  \n",
    ": unknown ( token -- thing Y|N) // Try to find the unknown token in __main__\n",
    "  py> getattr(sys.modules['__main__'],pop(),\"Ûnknôwn\") \n",
    "  py> str(tos())==\"Ûnknôwn\" if drop false else true then ;\n",
    "  /// here after, when FORTH come accross an unknown token, instead of alerting \n",
    "  /// it try to find the token in python __main__ module name space.\n",
    "\n",
    "\\ Redefine \\ command to print the comment line\n",
    "code \\ print(nexttoken('\\n')) end-code ''');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(np.array(irisX).reshape(-1,4), columns = iris.feature_names)    \n",
    "x = pd.DataFrame(iris.data, columns = iris.feature_names)    \n",
    "x[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(iris.target, columns = [\"target\"])    \n",
    "y[48:52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/pandas_input_fn\n",
    "\n",
    "tf.estimator.inputs.pandas_input_fn(\n",
    "    x,\n",
    "    y,\n",
    "    batch_size=64,\n",
    "    num_epochs=5,\n",
    "    shuffle=False,\n",
    "    queue_capacity=None,\n",
    "    num_threads=1,\n",
    "    target_column='target'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 照 Tutorial 執行 -- 一把就成功！\n",
    "\n",
    "直接把本 notebook 建個 hard link 到 c:\\Users\\hcche\\Documents\\GitHub\\models\\samples\\core\\get_started 去執行...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run premade_estimator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 開始照教材研讀\n",
    "    \n",
    "premade_estimator.py iris_data.py 都抓過來，他本來都放在 main() 內執行，不利 study 今予拆開，分段執行亦可，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"An Example of a DNNClassifier for the Iris dataset.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "\n",
    "import iris_data  # iris_data.py 在本目錄下 GitHub\\models\\samples\\core\\get_started\\iris_data.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這 argparse module 很常見 DeepSpeech 就有，這裡用不著吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--train_steps'], dest='train_steps', nargs=None, const=None, default=1000, type=<class 'int'>, choices=None, help='number of training steps', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch_size', default=100, type=int, help='batch size')\n",
    "parser.add_argument('--train_steps', default=1000, type=int,\n",
    "                    help='number of training steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 不能在 jupyter notebook 下直接跑，因為 argv 不如預期。\n",
    "from IPython.display import display,Image;display(Image('error1.jpg', width=700))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "研究一下 parser (argparse module) 怎麼回事兒 <== 只能在 python 用，ipython & jupyter notebook 都不行\n",
    "http://localhost:8888/notebooks/Documents/GitHub/models/samples/core/get_started/My%20estimator%20to%20predict%20iris.ipynb\n",
    "\n",
    "[x] 這是在 Jupyter Notebook 下記錄到的\n",
    "    OK Argv . cr\n",
    "    ['c:\\\\users\\\\hcche\\\\appdata\\\\local\\\\programs\\\\python\\\\python36\\\\lib\\\\site-packages\\\\ipykernel_launcher.py', '-f', 'C:\\\\Users\\\\hcche\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-d21c0b87-4db1-432d-82ca-cd398f2dd5ad.json']\n",
    "    OK \n",
    "    看起來有三個 args -- .py script 本身, -f , 還有一個 .json, 後兩個是 jupyter notebook 加的，難怪\n",
    "    要出問題。\n",
    "\n",
    "[x] 改用 ipython 直接跑 premade_estimator.py 看看 .... 成功。 \n",
    "    --> 那他看到的 Argv 是怎樣? -->['c:\\\\Users\\\\hcche\\\\Documents\\\\GitHub\\\\models\\\\samples\\\\core\\\\get_started\\\\premade_estimator.py']\n",
    "        等於是只有 argv[0] 的 .py script 本身一個 args 那就沒問題了。\n",
    "\n",
    "[x] 我猜測了一下，矇對了，這樣執行：\n",
    "    ipython premade_estimator.py --batch_size=1234 --train_steps=5678\n",
    "    搗出了一些 warning 警告說 args 可能有問題，但總之得到的 args 是：\n",
    "    argv 是這樣 \n",
    "    ['c:\\\\Users\\\\hcche\\\\Documents\\\\GitHub\\\\models\\\\samples\\\\core\\\\get_started\\\\premade_estimator.py']\n",
    "    args 是這樣\n",
    "    Namespace(batch_size=100, train_steps=1000)\n",
    "[x] 確定不能用 ipython, 用 python 以下皆可：\n",
    "    python premade_estimator.py --batch_size=64 --train_steps=1000\n",
    "    python premade_estimator.py --batch_size 64 --train_steps 1000\n",
    "\n",
    "反正我現在知道怎麼讓 jupyter notebook 能跑了! 改這樣即可： \n",
    "    args = parser.parse_args(\"\")  # 用 default 值\n",
    "    args = parser.parse_args([\"--batch_size=100\", \"--train_steps=1000\"])  # 代替 command line "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Command Line Arguments 要用模擬的\n",
    "Module argparse 只能在 python command line 跑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[x] 沒有指定時，自動取 default 值，真不知道這哪來的？看到了，從 parser 那邊 code 裡給的。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=100, train_steps=1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%f \\ [x] 沒有指定時，自動取 default 值，真不知道這哪來的？看到了，從 parser 那邊 code 裡給的。\n",
    "args = parser.parse_args([\"--batch_size=100\", \"--train_steps=1000\"])\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 研究  (train_x, train_y), (test_x, test_y) = iris_data.load_data()\n",
    "\n",
    "看出來了 iris_data.py 是把 150 筆資料切成 120 : 30 for training and testing respectively.\n",
    "這是個壞消息，他沒有像 sklearn 的自動切的那啥 function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " (train_x, train_y), (test_x, test_y) = iris_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0            6.4         2.8          5.6         2.2\n",
       "1            5.0         2.3          3.3         1.0\n",
       "2            4.9         2.5          4.5         1.7\n",
       "3            4.9         3.1          1.5         0.1\n",
       "4            5.7         3.8          1.7         0.3\n",
       "5            4.4         3.2          1.3         0.2\n",
       "6            5.4         3.4          1.5         0.4\n",
       "7            6.9         3.1          5.1         2.3\n",
       "8            6.7         3.1          4.4         1.4\n",
       "9            5.1         3.7          1.5         0.4\n",
       "10           5.2         2.7          3.9         1.4\n",
       "11           6.9         3.1          4.9         1.5\n",
       "12           5.8         4.0          1.2         0.2\n",
       "13           5.4         3.9          1.7         0.4\n",
       "14           7.7         3.8          6.7         2.2\n",
       "15           6.3         3.3          4.7         1.6\n",
       "16           6.8         3.2          5.9         2.3\n",
       "17           7.6         3.0          6.6         2.1\n",
       "18           6.4         3.2          5.3         2.3\n",
       "19           5.7         4.4          1.5         0.4\n",
       "20           6.7         3.3          5.7         2.1\n",
       "21           6.4         2.8          5.6         2.1\n",
       "22           5.4         3.9          1.3         0.4\n",
       "23           6.1         2.6          5.6         1.4\n",
       "24           7.2         3.0          5.8         1.6\n",
       "25           5.2         3.5          1.5         0.2\n",
       "26           5.8         2.6          4.0         1.2\n",
       "27           5.9         3.0          5.1         1.8\n",
       "28           5.4         3.0          4.5         1.5\n",
       "29           6.7         3.0          5.0         1.7\n",
       "..           ...         ...          ...         ...\n",
       "90           6.5         3.0          5.2         2.0\n",
       "91           6.1         2.8          4.7         1.2\n",
       "92           5.1         3.5          1.4         0.3\n",
       "93           4.6         3.1          1.5         0.2\n",
       "94           6.5         3.0          5.8         2.2\n",
       "95           4.6         3.4          1.4         0.3\n",
       "96           4.6         3.2          1.4         0.2\n",
       "97           7.7         2.8          6.7         2.0\n",
       "98           5.9         3.2          4.8         1.8\n",
       "99           5.1         3.8          1.6         0.2\n",
       "100          4.9         3.0          1.4         0.2\n",
       "101          4.9         2.4          3.3         1.0\n",
       "102          4.5         2.3          1.3         0.3\n",
       "103          5.8         2.7          4.1         1.0\n",
       "104          5.0         3.4          1.6         0.4\n",
       "105          5.2         3.4          1.4         0.2\n",
       "106          5.3         3.7          1.5         0.2\n",
       "107          5.0         3.6          1.4         0.2\n",
       "108          5.6         2.9          3.6         1.3\n",
       "109          4.8         3.1          1.6         0.2\n",
       "110          6.3         2.7          4.9         1.8\n",
       "111          5.7         2.8          4.1         1.3\n",
       "112          5.0         3.0          1.6         0.2\n",
       "113          6.3         3.3          6.0         2.5\n",
       "114          5.0         3.5          1.6         0.6\n",
       "115          5.5         2.6          4.4         1.2\n",
       "116          5.7         3.0          4.2         1.2\n",
       "117          4.4         2.9          1.4         0.2\n",
       "118          4.8         3.0          1.4         0.1\n",
       "119          5.5         2.4          3.7         1.0\n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%f train_x type . cr\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%f train_y type . cr\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0           5.9         3.0          4.2         1.5\n",
       "1           6.9         3.1          5.4         2.1\n",
       "2           5.1         3.3          1.7         0.5\n",
       "3           6.0         3.4          4.5         1.6\n",
       "4           5.5         2.5          4.0         1.3\n",
       "5           6.2         2.9          4.3         1.3\n",
       "6           5.5         4.2          1.4         0.2\n",
       "7           6.3         2.8          5.1         1.5\n",
       "8           5.6         3.0          4.1         1.3\n",
       "9           6.7         2.5          5.8         1.8\n",
       "10          7.1         3.0          5.9         2.1\n",
       "11          4.3         3.0          1.1         0.1\n",
       "12          5.6         2.8          4.9         2.0\n",
       "13          5.5         2.3          4.0         1.3\n",
       "14          6.0         2.2          4.0         1.0\n",
       "15          5.1         3.5          1.4         0.2\n",
       "16          5.7         2.6          3.5         1.0\n",
       "17          4.8         3.4          1.9         0.2\n",
       "18          5.1         3.4          1.5         0.2\n",
       "19          5.7         2.5          5.0         2.0\n",
       "20          5.4         3.4          1.7         0.2\n",
       "21          5.6         3.0          4.5         1.5\n",
       "22          6.3         2.9          5.6         1.8\n",
       "23          6.3         2.5          4.9         1.5\n",
       "24          5.8         2.7          3.9         1.2\n",
       "25          6.1         3.0          4.6         1.4\n",
       "26          5.2         4.1          1.5         0.1\n",
       "27          6.7         3.1          4.7         1.5\n",
       "28          6.7         3.3          5.7         2.5\n",
       "29          6.4         2.9          4.3         1.3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%f test_x type . cr\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     2\n",
       "2     0\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     0\n",
       "7     2\n",
       "8     1\n",
       "9     2\n",
       "10    2\n",
       "11    0\n",
       "12    2\n",
       "13    1\n",
       "14    1\n",
       "15    0\n",
       "16    1\n",
       "17    0\n",
       "18    0\n",
       "19    2\n",
       "20    0\n",
       "21    1\n",
       "22    2\n",
       "23    1\n",
       "24    1\n",
       "25    1\n",
       "26    0\n",
       "27    1\n",
       "28    2\n",
       "29    1\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%f test_y type . cr\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%f \\ [ ] 這是 feature columns, 我晚點可以嘗試把它弄成光一個 shape 為 (4,) 的單一 feature \n",
    "for key in train_x.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ] 這是 feature columns, 我晚點可以嘗試把它弄成光一個 shape 為 (4,) 的單一 feature\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%f \\ [ ] 這是 feature columns, 我晚點可以嘗試把它弄成光一個 shape 為 (4,) 的單一 feature \n",
    "my_feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "my_feature_columns    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "從 main 裡拆分出來，方便 tracing. 可看出若無指定 model directory 自動放在\n",
      "    AppData\\Local\\Temp\\tmpijrg8mkm <-- 每次都不一樣，這樣好嗎？\n",
      "以及本 classifier 的種種細節\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\hcche\\AppData\\Local\\Temp\\tmpatq8h0x5\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\hcche\\\\AppData\\\\Local\\\\Temp\\\\tmpatq8h0x5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001E352093DD8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "%f \\ 從 main 裡拆分出來，方便 tracing. 可看出若無指定 model directory 自動放在\n",
    "%f \\     AppData\\Local\\Temp\\tmpijrg8mkm <-- 每次都不一樣，這樣好嗎？\n",
    "%f \\ 以及本 classifier 的種種細節\n",
    "%f \\ \n",
    "\n",
    "# Build 2 hidden layer DNN with 10, 10 units respectively.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 10 nodes each.\n",
    "    hidden_units=[10, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%f \\ 複習一下 lambda --> \n",
    "%f \\ lambda 是個 function, 產生 key(i) 取 x 的第 i 個 element。用於 sorted() 時指定哪個當 key \n",
    "s = [('a', 3), ('b', 2), ('c', 1)]\n",
    "key = lambda x:x[1]\n",
    "print(sorted(s, key=key))\n",
    "%f \\ 單獨使用時，看起來不太一樣，其實做的是一樣的事情。\n",
    "%f key :> ([('a',3),('b',2),('c',1),('d',4)]) tib.\n",
    "%f key tib.\n",
    "%f key .source\n",
    "%f \\ 當沒有給 lambda argument 時，是怎樣？\n",
    "x = lambda:s\n",
    "%f x tib. \\ 直接傳回 : 之後的東西(執行後)的傳回值\n",
    "%f x type tib.\n",
    "%f \\ 查看 x 的 source code \n",
    "%f x .source\n",
    "%f x :> () tib.\n",
    "\n",
    "%f \\ 所以，input_fn = lambda:iris_data.train_input_fn(train_x, train_y,args.batch_size)\n",
    "%f \\ 當中的 iris_data.train_input_fn() 是傳回一個 function 但是該 function 的 argument 是活的，\n",
    "%f \\ 要延後到最後一秒鐘才確定，因此要用 lambda 或單純的 function 包一層用來指定 arguments。\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "這就開始訓練了 . . .\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\hcche\\AppData\\Local\\Temp\\tmpatq8h0x5\\model.ckpt.\n",
      "INFO:tensorflow:loss = 424.87692, step = 1\n",
      "INFO:tensorflow:global_step/sec: 735.74\n",
      "INFO:tensorflow:loss = 30.773207, step = 101 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 1044.63\n",
      "INFO:tensorflow:loss = 13.728249, step = 201 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1165.39\n",
      "INFO:tensorflow:loss = 11.526564, step = 301 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1018.25\n",
      "INFO:tensorflow:loss = 6.9922915, step = 401 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1044.63\n",
      "INFO:tensorflow:loss = 6.3475327, step = 501 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1061.12\n",
      "INFO:tensorflow:loss = 7.283091, step = 601 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1013.13\n",
      "INFO:tensorflow:loss = 4.3325872, step = 701 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1066.74\n",
      "INFO:tensorflow:loss = 5.825481, step = 801 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1083.94\n",
      "INFO:tensorflow:loss = 6.407595, step = 901 (0.093 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\hcche\\AppData\\Local\\Temp\\tmpatq8h0x5\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7.0532947.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1e352093b38>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%f \\ 這就開始訓練了 . . .  \n",
    "%f \\ \n",
    "\n",
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda:iris_data.train_input_fn(train_x, train_y,\n",
    "                                             args.batch_size),\n",
    "    steps=args.train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這時候的 classifier 已經受過訓練了! 可以接受考核了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-27-00:17:48\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hcche\\AppData\\Local\\Temp\\tmpatq8h0x5\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-27-00:17:48\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.96666664, average_loss = 0.060547315, global_step = 1000, loss = 1.8164195\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:iris_data.eval_input_fn(test_x, test_y,\n",
    "                                            args.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 0.967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%f \\ 複習一下 **eval_result 啥意思？\n",
    "%f eval_result . cr\n",
    "%f eval_result :> ['accuracy'] . cr\n",
    "{**eval_result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt = {'accuracy': 0.96666664, 'average_loss': 0.056607112, 'loss': 1.6982133, 'global_step': 1000}\n",
    "print('Test set accuracy: {loss:0.3f}'.format(**rslt))\n",
    "print('Test set accuracy: {:0.3f}'.format(r['accuracy']))\n",
    "print('Test set accuracy: {a:0.3f}'.format(**{'a': 11,'b': 22}))\n",
    "print('Test set accuracy: {b:0.3f}'.format(**{'a': 33,'b': 44}))\n",
    "%f \\ 最後一式拆解不成功，拆開來的寫法也沒意義，要嘛直接寫就好了。\n",
    "%f \\ print('Test set accuracy: {b:0.3f}'.format(({'a': 55},{'b': 66})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SepalLength', 'Setosa'),\n",
       " ('SepalWidth', 'Versicolor'),\n",
       " ('PetalLength', 'Virginica'),\n",
       " ('PetalWidth', 'Versicolor')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 這一段的意思是, 準備了 3 或 4 組資料 predict_x 分別的正確答案如 expected 所列\n",
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica','Versicolor']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9,6.2],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1,2.9],\n",
    "    'PetalLength': [1.7, 4.2, 5.4,4.3],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1,1.3],\n",
    "}\n",
    "\n",
    "[(i,j) for i,j in zip(predict_x,expected)]\n",
    "[i for i in zip(predict_x,expected)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(\n",
    "    input_fn=lambda:iris_data.eval_input_fn(predict_x,\n",
    "                                            labels=None,\n",
    "                                            batch_size=args.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 這樣寫也可以\n",
    "predictions = classifier.predict(\n",
    "    lambda:iris_data.eval_input_fn(predict_x,\n",
    "                                            labels=None,\n",
    "                                            batch_size=args.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%f predictions dir . cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以上 predictions 瞬間就取得了\n",
      "predictions tib. \\ ==> <generator object Estimator.predict at 0x000001E352888990> (<class 'generator'>)\n",
      "這 'generator' 用過就沒了，要再看一遍就得重新跑一次 classifier.predict()\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hcche\\AppData\\Local\\Temp\\tmpatq8h0x5\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'class_ids': array([0], dtype=int64),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 10.25738 ,   4.544209, -18.678862], dtype=float32),\n",
       "  'probabilities': array([9.9670863e-01, 3.2913175e-03, 2.7022056e-13], dtype=float32)},\n",
       " {'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-5.9797826,  1.2625508, -3.9928079], dtype=float32),\n",
       "  'probabilities': array([7.1141758e-04, 9.9409992e-01, 5.1886784e-03], dtype=float32)},\n",
       " {'class_ids': array([2], dtype=int64),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-11.815557 ,  -1.1373062,   1.4364924], dtype=float32),\n",
       "  'probabilities': array([1.6322867e-06, 7.0843734e-02, 9.2915463e-01], dtype=float32)},\n",
       " {'class_ids': array([1], dtype=int64),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-5.351184 ,  1.9237406, -5.0836687], dtype=float32),\n",
       "  'probabilities': array([6.915875e-04, 9.984047e-01, 9.037067e-04], dtype=float32)}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%f \\ 以上 predictions 瞬間就取得了\n",
    "%f predictions tib.\n",
    "%f \\ 這 'generator' 用過就沒了，要再看一遍就得重新跑一次 classifier.predict()\n",
    "pred = [i for i in predictions]\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hcche\\AppData\\Local\\Temp\\tmpatq8h0x5\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Prediction is \"Setosa\" (99.7%), expected \"Setosa\"\n",
      "\n",
      "Prediction is \"Versicolor\" (99.4%), expected \"Versicolor\"\n",
      "\n",
      "Prediction is \"Virginica\" (92.9%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print(template.format(iris_data.SPECIES[class_id],\n",
    "                          100 * probability, expec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "像拉拉鍊一樣，所有第一個一組、所有第二個一組、如此以往到哪個先結束為止\n",
      "z type tib. \\ ==> <class 'zip'> (<class 'type'>)\n",
      "z1 tib. \\ ==> [(1, 11, 'aa'), (2, 22, 'bb')] (<class 'list'>)\n",
      "z2 tib. \\ ==> [] (<class 'list'>)\n"
     ]
    }
   ],
   "source": [
    "zip?\n",
    "%f \\ zip() 傳回 iterator 像拉拉鍊一樣，所有第一個一組、所有第二個一組、如此以往到哪個先結束為止\n",
    "z = zip((1,2,3,4),(11,22,33),{'aa':1,'bb':2})\n",
    "%f z type tib.\n",
    "z1 = [i for i in z]\n",
    "z2 = [i for i in z]\n",
    "%f z1 tib.\n",
    "%f z2 tib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'class_ids': array([0], dtype=int64),\n",
       "   'classes': array([b'0'], dtype=object),\n",
       "   'logits': array([ 10.25738 ,   4.544209, -18.678862], dtype=float32),\n",
       "   'probabilities': array([9.9670863e-01, 3.2913175e-03, 2.7022056e-13], dtype=float32)},\n",
       "  'Setosa'),\n",
       " ({'class_ids': array([1], dtype=int64),\n",
       "   'classes': array([b'1'], dtype=object),\n",
       "   'logits': array([-5.9797826,  1.2625508, -3.9928079], dtype=float32),\n",
       "   'probabilities': array([7.1141758e-04, 9.9409992e-01, 5.1886784e-03], dtype=float32)},\n",
       "  'Versicolor'),\n",
       " ({'class_ids': array([2], dtype=int64),\n",
       "   'classes': array([b'2'], dtype=object),\n",
       "   'logits': array([-11.815557 ,  -1.1373062,   1.4364924], dtype=float32),\n",
       "   'probabilities': array([1.6322867e-06, 7.0843734e-02, 9.2915463e-01], dtype=float32)},\n",
       "  'Virginica'),\n",
       " ({'class_ids': array([1], dtype=int64),\n",
       "   'classes': array([b'1'], dtype=object),\n",
       "   'logits': array([-5.351184 ,  1.9237406, -5.0836687], dtype=float32),\n",
       "   'probabilities': array([6.915875e-04, 9.984047e-01, 9.037067e-04], dtype=float32)},\n",
       "  'Versicolor')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(pred_dict, expec) for pred_dict, expec in zip(pred, expected)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以賣弄這個方法時 pred （測試資料）的個數與 expected （標準結果）就要吻合才有意思。以下簡單就是 prediction 與標準答案的比對列出來看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction is \"Setosa\" (99.7%), expected \"Setosa\"\n",
      "\n",
      "Prediction is \"Versicolor\" (99.4%), expected \"Versicolor\"\n",
      "\n",
      "Prediction is \"Virginica\" (92.9%), expected \"Virginica\"\n",
      "\n",
      "Prediction is \"Versicolor\" (99.8%), expected \"Versicolor\"\n"
     ]
    }
   ],
   "source": [
    "for pred_dict, expec in zip(pred, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print(template.format(iris_data.SPECIES[class_id],\n",
    "                          100 * probability, expec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 都搞懂了，接下來把 feature 改一下，包裝成 pandas data-frame 試試看\n",
    "沒有必用管他什麼 petal sepal length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下是原本的教學程式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "    args = parser.parse_args(\"\")  # default is ([\"--batch_size=100\", \"--train_steps=1000\"])\n",
    "    # Fetch the data\n",
    "    (train_x, train_y), (test_x, test_y) = iris_data.load_data()\n",
    "\n",
    "    # Feature columns describe how to use the input.\n",
    "    my_feature_columns = []\n",
    "    for key in train_x.keys():\n",
    "        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "\n",
    "    # Build 2 hidden layer DNN with 10, 10 units respectively.\n",
    "    classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=my_feature_columns,\n",
    "        # Two hidden layers of 10 nodes each.\n",
    "        hidden_units=[10, 10],\n",
    "        # The model must choose between 3 classes.\n",
    "        n_classes=3)\n",
    "\n",
    "    # Train the Model.\n",
    "    classifier.train(\n",
    "        input_fn=lambda:iris_data.train_input_fn(train_x, train_y,\n",
    "                                                 args.batch_size),\n",
    "        steps=args.train_steps)\n",
    "\n",
    "    # Evaluate the model.\n",
    "    eval_result = classifier.evaluate(\n",
    "        input_fn=lambda:iris_data.eval_input_fn(test_x, test_y,\n",
    "                                                args.batch_size))\n",
    "\n",
    "    print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
    "\n",
    "    # Generate predictions from the model\n",
    "    expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "    predict_x = {\n",
    "        'SepalLength': [5.1, 5.9, 6.9],\n",
    "        'SepalWidth': [3.3, 3.0, 3.1],\n",
    "        'PetalLength': [1.7, 4.2, 5.4],\n",
    "        'PetalWidth': [0.5, 1.5, 2.1],\n",
    "    }\n",
    "\n",
    "    predictions = classifier.predict(\n",
    "        input_fn=lambda:iris_data.eval_input_fn(predict_x,\n",
    "                                                labels=None,\n",
    "                                                batch_size=args.batch_size))\n",
    "\n",
    "    template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "\n",
    "    for pred_dict, expec in zip(predictions, expected):\n",
    "        class_id = pred_dict['class_ids'][0]\n",
    "        probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "        print(template.format(iris_data.SPECIES[class_id],\n",
    "                              100 * probability, expec))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    tf.app.run(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "def maybe_download():\n",
    "    train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)\n",
    "    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
    "\n",
    "    return train_path, test_path\n",
    "\n",
    "def load_data(y_name='Species'):\n",
    "    \"\"\"Returns the iris dataset as (train_x, train_y), (test_x, test_y).\"\"\"\n",
    "    train_path, test_path = maybe_download()\n",
    "\n",
    "    train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "    train_x, train_y = train, train.pop(y_name)\n",
    "\n",
    "    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "    test_x, test_y = test, test.pop(y_name)\n",
    "\n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "\n",
    "\n",
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def eval_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
    "    features=dict(features)\n",
    "    if labels is None:\n",
    "        # No labels, use only features.\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels)\n",
    "\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "    # Batch the examples\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# The remainder of this file contains a simple example of a csv parser,\n",
    "#     implemented using the `Dataset` class.\n",
    "\n",
    "# `tf.parse_csv` sets the types of the outputs to match the examples given in\n",
    "#     the `record_defaults` argument.\n",
    "CSV_TYPES = [[0.0], [0.0], [0.0], [0.0], [0]]\n",
    "\n",
    "def _parse_line(line):\n",
    "    # Decode the line into its fields\n",
    "    fields = tf.decode_csv(line, record_defaults=CSV_TYPES)\n",
    "\n",
    "    # Pack the result into a dictionary\n",
    "    features = dict(zip(CSV_COLUMN_NAMES, fields))\n",
    "\n",
    "    # Separate the label from the features\n",
    "    label = features.pop('Species')\n",
    "\n",
    "    return features, label\n",
    "\n",
    "\n",
    "def csv_input_fn(csv_path, batch_size):\n",
    "    # Create a dataset containing the text lines.\n",
    "    dataset = tf.data.TextLineDataset(csv_path).skip(1)\n",
    "\n",
    "    # Parse each line.\n",
    "    dataset = dataset.map(_parse_line)\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ----- play ground -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates %%csv cell magic. See http://ipython-books.github.io/14-creating-an-ipython-extension-with-custom-magic-commands\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from IPython.core.magic import (register_cell_magic)\n",
    "@register_cell_magic\n",
    "def csv(line, cell):\n",
    "    return pd.read_csv(StringIO(cell), sep=line, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%csv \\s+\n",
    "a b c\n",
    "1 2 3\n",
    "4 5 6\n",
    "7 8 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
